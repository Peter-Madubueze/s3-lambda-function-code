import json
import boto3
import os

# Initialize AWS clients
s3_client = boto3.client('s3')
sns_client = boto3.client('sns')

# SNS topic ARN (to notify the operator)
SNS_TOPIC_ARN = os.environ['SNS_TOPIC_ARN']  # You can set this in Lambda environment variables

def lambda_handler(event, context):
    # Extract bucket name and object key from the event
    bucket_name = event['Records'][0]['s3']['bucket']['name']
    object_key = event['Records'][0]['s3']['object']['key']

    try:
        # Fetch object metadata to get the size of the uploaded file
        response = s3_client.head_object(Bucket=bucket_name, Key=object_key)
        object_size = response['ContentLength']  # Size in bytes

        # Check if the file size is greater than 10GB (10GB = 10 * 1024 * 1024 * 1024 bytes)
        if object_size > 10 * 1024 * 1024 * 1024:
            # Send SNS notification if the object is larger than 10GB
            message = f"Warning: An object with size {object_size / (1024 ** 3):.2f} GB was uploaded to S3 bucket '{bucket_name}'. Object Key: {object_key}"
            sns_client.publish(
                TopicArn=SNS_TOPIC_ARN,
                Message=message,
                Subject='Large File Upload Notification'
            )
            print(f"Notification sent for large file upload: {object_key}, size: {object_size / (1024 ** 3):.2f} GB")
        else:
            print(f"Object '{object_key}' is within size limits: {object_size / (1024 ** 3):.2f} GB")
    
    except Exception as e:
        print(f"Error occurred: {str(e)}")
        raise e
